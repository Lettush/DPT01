{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"adult.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "Data inspection is the initial review of a dataset to find missing values, incorrect data types, and gather basic statistics, providing insights into its quality and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Specific character as null\n",
    "(df == '?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial analysis before cleaning\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "Cleaning data involves eliminating or rectifying inaccuracies, inconsistencies, and missing values within your dataset, utilizing techniques such as handling missing values via deletion or imputation, rectifying data types, and detecting and eliminating duplicate entries, ultimately resulting in more precise and dependable analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective number 1: turn question marks into null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null representatives with null\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null values with a placeholder values\n",
    "df['occupation'] = df['occupation'].fillna(\"Unemployed\")\n",
    "df['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Trimming and Cleaning Text Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove beginning and ending whitespaces\n",
    "df['workclass'] = df['workclass'].str.strip()\n",
    "df['workclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace text with other text\n",
    "occupation_mapping = {\n",
    "\t'Machine-op-inspct': 'Machine Operator',\n",
    "\t'Farming-fishing': 'Farming and Fishing',\n",
    "\t'Protective-serv': 'Protective Services'\n",
    "}\n",
    "\n",
    "df['occupation'].map(occupation_mapping).fillna(df['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace parts of strings\n",
    "df['occupation'].replace('-', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing column data types\n",
    "df['income'] = df['income'].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Renaming columns and Reindexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change columns names\n",
    "df.rename(columns={'native-country': \"Country\", 'hours-per-week': 'Working Hours'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing - Only focusing on certain columns\n",
    "df.reindex(columns=['income', 'age', 'gender', 'Country', 'occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unique values of a column\n",
    "df['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "\n",
    "# Row (single)\n",
    "shortened_df = df.drop(0)\n",
    "\n",
    "# Row (mulitple)\n",
    "shortened_df = df.drop([0, 1, 2])\n",
    "\n",
    "# Column (single)\n",
    "shortened_df = df.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Column (mulitple)\n",
    "shortened_df = df.drop(['fnlwgt', 'capital-gain', 'capital-loss'], axis=1)\n",
    "\n",
    "# columns and rows\n",
    "shortened_df = df.drop([0, 1, 3]).drop(['education', 'marital-status'], axis=1)\n",
    "shortened_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Duplicates**\n",
    "\n",
    "Identifying and removing duplicate records are crucial for maintaining data quality. Pandas provides .duplicated() and .drop_duplicates() for finding and removing duplicates, ensuring each data point is unique for accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aggregating Data** (.groupby)\n",
    "\n",
    "Aggregating data involves summarizing data points into meaningful statistics, such as averages, sums, or counts, which can be achieved using GroupBy operations or pivot tables. This helps in understanding the dataset at a higher level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GroupBy operation: Average age by occupation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of occupation to category instead of object\n",
    "df['occupation'] = df['occupation'].astype('category')\n",
    "\n",
    "# Getting the unique values for occupation\n",
    "df['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the average age per occupation\n",
    "age_series = df.groupby('occupation')['age'].mean()\n",
    "age_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot table: Average hours per week by income and gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merging and Joining Data**\n",
    "\n",
    "Merging and joining data with pandas involves combining different datasets based on common columns or indices, enabling a comprehensive analysis of related information spread across multiple sources. pandas supports various types of joins: left, right, inner, and outer, mimicking SQL join operations and providing flexibility in how datasets are combined.\n",
    "\n",
    "**Types of Joins**\n",
    "- Left Join (left): Includes all records from the left DataFrame and matched records from the right DataFrame. Unmatched records in the right DataFrame are not included.\n",
    "- Right Join (right): Includes all records from the right DataFrame and matched records from the left DataFrame. Unmatched records in the left DataFrame are not included.\n",
    "- Inner Join (inner): Only includes records with matching values in both DataFrames, excluding all unmatched records.\n",
    "- Outer Join (outer): Includes all records from both DataFrames, with unmatched records filled with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employment = pd.DataFrame({\n",
    "  'occupation': ['Adm-clerical', 'Exec-managerial', 'Software-engineer'],\n",
    "  'sector': ['Administrative', 'Executive', 'Software']\n",
    "})\n",
    "\n",
    "df_employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Join\n",
    "# Only include records with matching values in both DataFrames\n",
    "\n",
    "df_merged = df.merge(df_employment, on=\"occupation\", how=\"inner\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer Join / Full Join\n",
    "# Includes all records from Both DFs, with unmatched records filled with NaN/null\n",
    "\n",
    "df_merged = df.merge(df_employment, on=\"occupation\", how=\"outer\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join\n",
    "# Includes all records from the left DataFrame and only matched records from the right DataFrame.\n",
    "df_merged = df.merge(df_employment, on=\"occupation\", how=\"left\")\n",
    "df_merged\n",
    "\n",
    "# Right Join\n",
    "# Includes all records from the right DataFrame and only matched records from the left DataFrame.\n",
    "df_merged = df.merge(df_employment, on=\"occupation\", how=\"right\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if occupation is still in the merged DF\n",
    "df_merged[df_merged['occupation'] == 'Protective-serv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if occupation is still in the merged DF\n",
    "df_merged[df_merged['sector'] == 'Software']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
